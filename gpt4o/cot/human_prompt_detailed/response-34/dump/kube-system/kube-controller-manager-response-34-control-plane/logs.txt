==== START logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-34-control-plane ====
I0107 23:06:03.391651       1 serving.go:386] Generated self-signed cert in-memory
I0107 23:06:03.657354       1 controllermanager.go:197] "Starting" version="v1.31.0"
I0107 23:06:03.657394       1 controllermanager.go:199] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0107 23:06:03.659027       1 dynamic_cafile_content.go:160] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I0107 23:06:03.659030       1 dynamic_cafile_content.go:160] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I0107 23:06:03.659202       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0107 23:06:03.659220       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0107 23:06:03.659375       1 leaderelection.go:254] attempting to acquire leader lease kube-system/kube-controller-manager...
E0107 23:06:05.444553       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
E0107 23:06:07.825255       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
I0107 23:06:10.705329       1 leaderelection.go:268] successfully acquired lease kube-system/kube-controller-manager
I0107 23:06:10.705419       1 event.go:389] "Event occurred" object="kube-system/kube-controller-manager" fieldPath="" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="response-34-control-plane_b65b1df3-ff23-4aad-988f-5ae80a8c551f became leader"
I0107 23:06:11.708610       1 controllermanager.go:797] "Started controller" controller="serviceaccount-token-controller"
I0107 23:06:11.708628       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0107 23:06:11.727492       1 controllermanager.go:797] "Started controller" controller="deployment-controller"
I0107 23:06:11.727614       1 deployment_controller.go:173] "Starting controller" logger="deployment-controller" controller="deployment"
I0107 23:06:11.727638       1 shared_informer.go:313] Waiting for caches to sync for deployment
I0107 23:06:11.741103       1 controllermanager.go:797] "Started controller" controller="statefulset-controller"
I0107 23:06:11.741257       1 stateful_set.go:166] "Starting stateful set controller" logger="statefulset-controller"
I0107 23:06:11.741291       1 shared_informer.go:313] Waiting for caches to sync for stateful set
I0107 23:06:11.758868       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-serving"
I0107 23:06:11.758896       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
I0107 23:06:11.758896       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0107 23:06:11.759042       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-client"
I0107 23:06:11.759068       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-client
I0107 23:06:11.759093       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0107 23:06:11.759204       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kube-apiserver-client"
I0107 23:06:11.759226       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
I0107 23:06:11.759240       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0107 23:06:11.759390       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-signing-controller"
I0107 23:06:11.759478       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-legacy-unknown"
I0107 23:06:11.759507       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
I0107 23:06:11.759525       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0107 23:06:11.761220       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0107 23:06:11.761270       1 cleaner.go:83] "Starting CSR cleaner controller" logger="certificatesigningrequest-cleaner-controller"
I0107 23:06:11.773276       1 controllermanager.go:797] "Started controller" controller="ttl-after-finished-controller"
I0107 23:06:11.773309       1 ttlafterfinished_controller.go:112] "Starting TTL after finished controller" logger="ttl-after-finished-controller"
I0107 23:06:11.773318       1 shared_informer.go:313] Waiting for caches to sync for TTL after finished
I0107 23:06:11.789387       1 controllermanager.go:797] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
I0107 23:06:11.789486       1 legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller" logger="legacy-serviceaccount-token-cleaner-controller"
I0107 23:06:11.789530       1 shared_informer.go:313] Waiting for caches to sync for legacy-service-account-token-cleaner
I0107 23:06:11.810968       1 shared_informer.go:320] Caches are synced for tokens
I0107 23:06:11.817777       1 controllermanager.go:797] "Started controller" controller="validatingadmissionpolicy-status-controller"
I0107 23:06:11.818339       1 shared_informer.go:313] Waiting for caches to sync for validatingadmissionpolicy-status
I0107 23:06:11.870321       1 controllermanager.go:797] "Started controller" controller="endpointslice-mirroring-controller"
I0107 23:06:11.870363       1 endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller" logger="endpointslice-mirroring-controller"
I0107 23:06:11.870374       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice_mirroring
I0107 23:06:11.892315       1 controllermanager.go:797] "Started controller" controller="serviceaccount-controller"
I0107 23:06:11.892386       1 serviceaccounts_controller.go:114] "Starting service account controller" logger="serviceaccount-controller"
I0107 23:06:11.892410       1 shared_informer.go:313] Waiting for caches to sync for service account
I0107 23:06:11.893911       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-approving-controller"
I0107 23:06:11.894018       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-approving-controller" name="csrapproving"
I0107 23:06:11.894032       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrapproving
I0107 23:06:11.906146       1 node_lifecycle_controller.go:430] "Controller will reconcile labels" logger="node-lifecycle-controller"
I0107 23:06:11.906184       1 controllermanager.go:797] "Started controller" controller="node-lifecycle-controller"
I0107 23:06:11.906201       1 core.go:298] "Warning: configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes." logger="node-route-controller"
I0107 23:06:11.906207       1 controllermanager.go:775] "Warning: skipping controller" controller="node-route-controller"
I0107 23:06:11.906364       1 node_lifecycle_controller.go:464] "Sending events to api server" logger="node-lifecycle-controller"
I0107 23:06:11.906431       1 node_lifecycle_controller.go:475] "Starting node controller" logger="node-lifecycle-controller"
I0107 23:06:11.906451       1 shared_informer.go:313] Waiting for caches to sync for taint
I0107 23:06:11.924966       1 controllermanager.go:797] "Started controller" controller="persistentvolume-protection-controller"
I0107 23:06:11.924985       1 pv_protection_controller.go:81] "Starting PV protection controller" logger="persistentvolume-protection-controller"
I0107 23:06:11.924996       1 shared_informer.go:313] Waiting for caches to sync for PV protection
I0107 23:06:12.022684       1 controllermanager.go:797] "Started controller" controller="ephemeral-volume-controller"
I0107 23:06:12.022746       1 controller.go:173] "Starting ephemeral volume controller" logger="ephemeral-volume-controller"
I0107 23:06:12.022755       1 shared_informer.go:313] Waiting for caches to sync for ephemeral
I0107 23:06:12.182606       1 controllermanager.go:797] "Started controller" controller="replicationcontroller-controller"
I0107 23:06:12.182839       1 replica_set.go:217] "Starting controller" logger="replicationcontroller-controller" name="replicationcontroller"
I0107 23:06:12.182935       1 shared_informer.go:313] Waiting for caches to sync for ReplicationController
I0107 23:06:12.411357       1 garbagecollector.go:146] "Starting controller" logger="garbage-collector-controller" controller="garbagecollector"
I0107 23:06:12.411388       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0107 23:06:12.411403       1 controllermanager.go:797] "Started controller" controller="garbage-collector-controller"
I0107 23:06:12.411408       1 graph_builder.go:351] "Running" logger="garbage-collector-controller" component="GraphBuilder"
E0107 23:06:12.461771       1 core.go:274] "Failed to start cloud node lifecycle controller" err="no cloud provider provided" logger="cloud-node-lifecycle-controller"
I0107 23:06:12.461811       1 controllermanager.go:775] "Warning: skipping controller" controller="cloud-node-lifecycle-controller"
I0107 23:06:12.717535       1 controllermanager.go:797] "Started controller" controller="clusterrole-aggregation-controller"
I0107 23:06:12.717582       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
I0107 23:06:12.717603       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
I0107 23:06:12.717643       1 clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller" logger="clusterrole-aggregation-controller"
I0107 23:06:12.717682       1 shared_informer.go:313] Waiting for caches to sync for ClusterRoleAggregator
I0107 23:06:12.866664       1 controllermanager.go:797] "Started controller" controller="pod-garbage-collector-controller"
I0107 23:06:12.866708       1 gc_controller.go:99] "Starting GC controller" logger="pod-garbage-collector-controller"
I0107 23:06:12.866715       1 shared_informer.go:313] Waiting for caches to sync for GC
I0107 23:06:13.168928       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="rolebindings.rbac.authorization.k8s.io"
I0107 23:06:13.169005       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="csistoragecapacities.storage.k8s.io"
I0107 23:06:13.169068       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="statefulsets.apps"
I0107 23:06:13.169119       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="networkpolicies.networking.k8s.io"
I0107 23:06:13.169251       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="deployments.apps"
I0107 23:06:13.169309       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="horizontalpodautoscalers.autoscaling"
I0107 23:06:13.169362       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpointslices.discovery.k8s.io"
I0107 23:06:13.169452       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="limitranges"
I0107 23:06:13.169509       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpoints"
I0107 23:06:13.169545       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="cronjobs.batch"
I0107 23:06:13.169627       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="podtemplates"
I0107 23:06:13.169671       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="controllerrevisions.apps"
W0107 23:06:13.169703       1 shared_informer.go:597] resyncPeriod 18h41m18.324937241s is smaller than resyncCheckPeriod 23h52m56.96170758s and the informer has already started. Changing it to 23h52m56.96170758s
I0107 23:06:13.169777       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="serviceaccounts"
I0107 23:06:13.169819       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="daemonsets.apps"
I0107 23:06:13.169846       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="roles.rbac.authorization.k8s.io"
I0107 23:06:13.169917       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="ingresses.networking.k8s.io"
W0107 23:06:13.169979       1 shared_informer.go:597] resyncPeriod 14h54m19.673107513s is smaller than resyncCheckPeriod 23h52m56.96170758s and the informer has already started. Changing it to 23h52m56.96170758s
I0107 23:06:13.170055       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="poddisruptionbudgets.policy"
I0107 23:06:13.170092       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="leases.coordination.k8s.io"
I0107 23:06:13.170165       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="replicasets.apps"
I0107 23:06:13.170237       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="jobs.batch"
I0107 23:06:13.170298       1 controllermanager.go:797] "Started controller" controller="resourcequota-controller"
I0107 23:06:13.170396       1 resource_quota_controller.go:300] "Starting resource quota controller" logger="resourcequota-controller"
I0107 23:06:13.170507       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0107 23:06:13.170542       1 resource_quota_monitor.go:308] "QuotaMonitor running" logger="resourcequota-controller"
I0107 23:06:13.211590       1 controllermanager.go:797] "Started controller" controller="taint-eviction-controller"
I0107 23:06:13.211715       1 taint_eviction.go:281] "Starting" logger="taint-eviction-controller" controller="taint-eviction-controller"
I0107 23:06:13.211801       1 taint_eviction.go:287] "Sending events to api server" logger="taint-eviction-controller"
I0107 23:06:13.211816       1 shared_informer.go:313] Waiting for caches to sync for taint-eviction-controller
I0107 23:06:13.465544       1 controllermanager.go:797] "Started controller" controller="namespace-controller"
I0107 23:06:13.465674       1 namespace_controller.go:202] "Starting namespace controller" logger="namespace-controller"
I0107 23:06:13.465691       1 shared_informer.go:313] Waiting for caches to sync for namespace
I0107 23:06:13.616621       1 controllermanager.go:797] "Started controller" controller="job-controller"
I0107 23:06:13.616655       1 job_controller.go:226] "Starting job controller" logger="job-controller"
I0107 23:06:13.616665       1 shared_informer.go:313] Waiting for caches to sync for job
I0107 23:06:13.765830       1 controllermanager.go:797] "Started controller" controller="replicaset-controller"
I0107 23:06:13.765886       1 replica_set.go:217] "Starting controller" logger="replicaset-controller" name="replicaset"
I0107 23:06:13.765893       1 shared_informer.go:313] Waiting for caches to sync for ReplicaSet
I0107 23:06:13.914839       1 controllermanager.go:797] "Started controller" controller="token-cleaner-controller"
I0107 23:06:13.914889       1 tokencleaner.go:117] "Starting token cleaner controller" logger="token-cleaner-controller"
I0107 23:06:13.914895       1 shared_informer.go:313] Waiting for caches to sync for token_cleaner
I0107 23:06:13.914900       1 shared_informer.go:320] Caches are synced for token_cleaner
I0107 23:06:14.064618       1 range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses" logger="node-ipam-controller"
I0107 23:06:14.064663       1 controllermanager.go:797] "Started controller" controller="node-ipam-controller"
I0107 23:06:14.064749       1 node_ipam_controller.go:141] "Starting ipam controller" logger="node-ipam-controller"
I0107 23:06:14.064770       1 shared_informer.go:313] Waiting for caches to sync for node
I0107 23:06:14.221141       1 controllermanager.go:797] "Started controller" controller="persistentvolume-attach-detach-controller"
I0107 23:06:14.221183       1 attach_detach_controller.go:338] "Starting attach detach controller" logger="persistentvolume-attach-detach-controller"
I0107 23:06:14.221192       1 shared_informer.go:313] Waiting for caches to sync for attach detach
I0107 23:06:14.366786       1 controllermanager.go:797] "Started controller" controller="endpointslice-controller"
I0107 23:06:14.366848       1 endpointslice_controller.go:281] "Starting endpoint slice controller" logger="endpointslice-controller"
I0107 23:06:14.366856       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice
I0107 23:06:14.515598       1 controllermanager.go:797] "Started controller" controller="persistentvolume-binder-controller"
I0107 23:06:14.515673       1 pv_controller_base.go:308] "Starting persistent volume controller" logger="persistentvolume-binder-controller"
I0107 23:06:14.515695       1 shared_informer.go:313] Waiting for caches to sync for persistent volume
I0107 23:06:14.665215       1 controllermanager.go:797] "Started controller" controller="persistentvolume-expander-controller"
I0107 23:06:14.665244       1 expand_controller.go:328] "Starting expand controller" logger="persistentvolume-expander-controller"
I0107 23:06:14.665253       1 shared_informer.go:313] Waiting for caches to sync for expand
I0107 23:06:14.665244       1 controllermanager.go:775] "Warning: skipping controller" controller="storage-version-migrator-controller"
I0107 23:06:14.818396       1 controllermanager.go:797] "Started controller" controller="cronjob-controller"
I0107 23:06:14.818494       1 cronjob_controllerv2.go:145] "Starting cronjob controller v2" logger="cronjob-controller"
I0107 23:06:14.818516       1 shared_informer.go:313] Waiting for caches to sync for cronjob
I0107 23:06:15.110630       1 controllermanager.go:797] "Started controller" controller="horizontal-pod-autoscaler-controller"
I0107 23:06:15.110677       1 horizontal.go:201] "Starting HPA controller" logger="horizontal-pod-autoscaler-controller"
I0107 23:06:15.110685       1 shared_informer.go:313] Waiting for caches to sync for HPA
I0107 23:06:15.310829       1 controllermanager.go:797] "Started controller" controller="disruption-controller"
I0107 23:06:15.310898       1 disruption.go:452] "Sending events to api server." logger="disruption-controller"
I0107 23:06:15.310932       1 disruption.go:463] "Starting disruption controller" logger="disruption-controller"
I0107 23:06:15.310956       1 shared_informer.go:313] Waiting for caches to sync for disruption
I0107 23:06:15.464334       1 controllermanager.go:797] "Started controller" controller="bootstrap-signer-controller"
I0107 23:06:15.464386       1 shared_informer.go:313] Waiting for caches to sync for bootstrap_signer
E0107 23:06:15.618950       1 core.go:105] "Failed to start service controller" err="WARNING: no cloud provider provided, services of type LoadBalancer will fail" logger="service-lb-controller"
I0107 23:06:15.618976       1 controllermanager.go:775] "Warning: skipping controller" controller="service-lb-controller"
I0107 23:06:15.618983       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
I0107 23:06:15.767324       1 controllermanager.go:797] "Started controller" controller="endpoints-controller"
I0107 23:06:15.767397       1 endpoints_controller.go:182] "Starting endpoint controller" logger="endpoints-controller"
I0107 23:06:15.767419       1 shared_informer.go:313] Waiting for caches to sync for endpoint
I0107 23:06:15.922690       1 controllermanager.go:797] "Started controller" controller="ttl-controller"
I0107 23:06:15.922755       1 ttl_controller.go:127] "Starting TTL controller" logger="ttl-controller"
I0107 23:06:15.922762       1 shared_informer.go:313] Waiting for caches to sync for TTL
I0107 23:06:16.080993       1 controllermanager.go:797] "Started controller" controller="persistentvolumeclaim-protection-controller"
I0107 23:06:16.081059       1 pvc_protection_controller.go:105] "Starting PVC protection controller" logger="persistentvolumeclaim-protection-controller"
I0107 23:06:16.081334       1 shared_informer.go:313] Waiting for caches to sync for PVC protection
I0107 23:06:16.222622       1 controllermanager.go:797] "Started controller" controller="root-ca-certificate-publisher-controller"
I0107 23:06:16.222663       1 publisher.go:107] "Starting root CA cert publisher controller" logger="root-ca-certificate-publisher-controller"
I0107 23:06:16.222670       1 shared_informer.go:313] Waiting for caches to sync for crt configmap
I0107 23:06:16.375285       1 controllermanager.go:797] "Started controller" controller="daemonset-controller"
I0107 23:06:16.375432       1 daemon_controller.go:294] "Starting daemon sets controller" logger="daemonset-controller"
I0107 23:06:16.375456       1 shared_informer.go:313] Waiting for caches to sync for daemon sets
I0107 23:06:16.378343       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0107 23:06:16.378988       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-control-plane\" does not exist"
I0107 23:06:16.385831       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0107 23:06:16.390342       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0107 23:06:16.393080       1 shared_informer.go:320] Caches are synced for service account
I0107 23:06:16.394276       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0107 23:06:16.406492       1 shared_informer.go:320] Caches are synced for taint
I0107 23:06:16.406577       1 node_lifecycle_controller.go:1232] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0107 23:06:16.406696       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-control-plane"
I0107 23:06:16.406736       1 node_lifecycle_controller.go:1036] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0107 23:06:16.411049       1 shared_informer.go:320] Caches are synced for disruption
I0107 23:06:16.412213       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0107 23:06:16.416672       1 shared_informer.go:320] Caches are synced for persistent volume
I0107 23:06:16.416790       1 shared_informer.go:320] Caches are synced for job
I0107 23:06:16.419010       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0107 23:06:16.419030       1 shared_informer.go:320] Caches are synced for cronjob
I0107 23:06:16.423400       1 shared_informer.go:320] Caches are synced for TTL
I0107 23:06:16.423433       1 shared_informer.go:320] Caches are synced for ephemeral
I0107 23:06:16.423442       1 shared_informer.go:320] Caches are synced for crt configmap
I0107 23:06:16.425622       1 shared_informer.go:320] Caches are synced for PV protection
I0107 23:06:16.428618       1 shared_informer.go:320] Caches are synced for deployment
I0107 23:06:16.459212       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0107 23:06:16.459243       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0107 23:06:16.459271       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0107 23:06:16.460373       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0107 23:06:16.465323       1 shared_informer.go:320] Caches are synced for expand
I0107 23:06:16.465349       1 shared_informer.go:320] Caches are synced for node
I0107 23:06:16.465378       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0107 23:06:16.465387       1 range_allocator.go:171] "Sending events to api server" logger="node-ipam-controller"
I0107 23:06:16.465444       1 range_allocator.go:177] "Starting range CIDR allocator" logger="node-ipam-controller"
I0107 23:06:16.465464       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0107 23:06:16.465470       1 shared_informer.go:320] Caches are synced for cidrallocator
I0107 23:06:16.465792       1 shared_informer.go:320] Caches are synced for namespace
I0107 23:06:16.465923       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0107 23:06:16.467624       1 shared_informer.go:320] Caches are synced for GC
I0107 23:06:16.467662       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0107 23:06:16.467727       1 shared_informer.go:320] Caches are synced for endpoint
I0107 23:06:16.470574       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0107 23:06:16.474244       1 shared_informer.go:320] Caches are synced for TTL after finished
I0107 23:06:16.481504       1 shared_informer.go:320] Caches are synced for PVC protection
I0107 23:06:16.484087       1 shared_informer.go:320] Caches are synced for ReplicationController
I0107 23:06:16.510808       1 shared_informer.go:320] Caches are synced for HPA
I0107 23:06:16.515546       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-control-plane" podCIDRs=["10.244.0.0/24"]
I0107 23:06:16.515586       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0107 23:06:16.515606       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0107 23:06:16.542353       1 shared_informer.go:320] Caches are synced for stateful set
I0107 23:06:16.576476       1 shared_informer.go:320] Caches are synced for daemon sets
I0107 23:06:16.618201       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0107 23:06:16.621512       1 shared_informer.go:320] Caches are synced for attach detach
I0107 23:06:16.671281       1 shared_informer.go:320] Caches are synced for resource quota
I0107 23:06:16.678574       1 shared_informer.go:320] Caches are synced for resource quota
I0107 23:06:17.076437       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0107 23:06:17.086811       1 shared_informer.go:320] Caches are synced for garbage collector
I0107 23:06:17.112087       1 shared_informer.go:320] Caches are synced for garbage collector
I0107 23:06:17.112121       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0107 23:06:17.851847       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="677.547518ms"
I0107 23:06:17.852144       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="606.632995ms"
I0107 23:06:17.975897       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="124.003988ms"
I0107 23:06:17.975970       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="34.901µs"
I0107 23:06:17.975903       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="123.724975ms"
I0107 23:06:17.976018       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="22.502µs"
I0107 23:06:17.976051       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="14.301µs"
I0107 23:06:17.976069       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="33.202µs"
I0107 23:06:19.961630       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-worker\" does not exist"
I0107 23:06:19.997469       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-worker2\" does not exist"
I0107 23:06:20.149722       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-worker" podCIDRs=["10.244.1.0/24"]
I0107 23:06:20.149745       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:20.150164       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:20.354327       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:20.382629       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-worker2" podCIDRs=["10.244.2.0/24"]
I0107 23:06:20.382659       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:20.382688       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:20.382716       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:20.580901       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:20.580934       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:20.835352       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:20.835438       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:21.407370       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-worker2"
I0107 23:06:21.407411       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-worker"
I0107 23:06:22.290497       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="480.472404ms"
I0107 23:06:22.715743       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="425.19552ms"
I0107 23:06:22.716072       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="674.290258ms"
I0107 23:06:23.525600       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="809.480921ms"
I0107 23:06:23.525695       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="49.301µs"
I0107 23:06:23.525760       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="809.917035ms"
I0107 23:06:23.525880       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="65.202µs"
I0107 23:06:30.769602       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:30.933647       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:36.102944       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0107 23:06:36.143108       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0107 23:06:36.263158       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="49.001µs"
I0107 23:06:36.292668       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="32.501µs"
I0107 23:06:36.292680       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="41.801µs"
I0107 23:06:36.409007       1 node_lifecycle_controller.go:1055] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0107 23:06:36.517243       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="55.101µs"
I0107 23:06:36.653461       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="40.701µs"
I0107 23:06:36.733673       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="34.701µs"
I0107 23:06:41.095590       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:41.095692       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-34-worker"
I0107 23:06:41.211884       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:06:41.394905       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="32.101µs"
I0107 23:06:41.598876       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="31.9µs"
I0107 23:06:41.690827       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:41.690915       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-34-worker"
I0107 23:06:41.847858       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0107 23:06:50.325187       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="55.002µs"
I0107 23:06:50.512555       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="77.404964ms"
I0107 23:06:50.633952       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="117.585691ms"
I0107 23:06:50.634077       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="46.901µs"
I0107 23:06:52.390170       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="132.666409ms"
I0107 23:06:52.390286       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="34.502µs"
I0107 23:07:05.504889       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="40.301µs"
I0107 23:07:05.592350       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="40.401µs"
I0107 23:07:07.380667       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="38.202µs"
I0107 23:07:21.755255       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0107 23:07:23.411144       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="42.302µs"
I0107 23:07:45.867093       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="17.256653ms"
I0107 23:07:45.867170       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-74dc679756" duration="38.601µs"
I0107 23:07:47.519385       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="16.657434ms"
I0107 23:07:47.519491       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="21.601µs"
I0107 23:07:52.257104       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
==== END logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-34-control-plane ====
