==== START logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-34-control-plane ====
I0103 03:52:09.439593       1 serving.go:386] Generated self-signed cert in-memory
I0103 03:52:09.801347       1 controllermanager.go:197] "Starting" version="v1.31.0"
I0103 03:52:09.801368       1 controllermanager.go:199] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0103 03:52:09.803055       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0103 03:52:09.803217       1 leaderelection.go:254] attempting to acquire leader lease kube-system/kube-controller-manager...
I0103 03:52:09.803454       1 dynamic_cafile_content.go:160] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I0103 03:52:09.803524       1 dynamic_cafile_content.go:160] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I0103 03:52:09.803599       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E0103 03:52:11.554874       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
I0103 03:52:14.118242       1 leaderelection.go:268] successfully acquired lease kube-system/kube-controller-manager
I0103 03:52:14.118396       1 event.go:389] "Event occurred" object="kube-system/kube-controller-manager" fieldPath="" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="response-34-control-plane_1b187b70-4b02-4d58-b3a1-92f2b3c3807a became leader"
I0103 03:52:14.119467       1 controllermanager.go:797] "Started controller" controller="serviceaccount-token-controller"
I0103 03:52:14.119475       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0103 03:52:14.133730       1 controllermanager.go:797] "Started controller" controller="horizontal-pod-autoscaler-controller"
I0103 03:52:14.133773       1 horizontal.go:201] "Starting HPA controller" logger="horizontal-pod-autoscaler-controller"
I0103 03:52:14.133782       1 shared_informer.go:313] Waiting for caches to sync for HPA
I0103 03:52:14.139311       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-approving-controller"
I0103 03:52:14.139410       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-approving-controller" name="csrapproving"
I0103 03:52:14.139435       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrapproving
I0103 03:52:14.145173       1 controllermanager.go:797] "Started controller" controller="token-cleaner-controller"
I0103 03:52:14.145235       1 tokencleaner.go:117] "Starting token cleaner controller" logger="token-cleaner-controller"
I0103 03:52:14.145243       1 shared_informer.go:313] Waiting for caches to sync for token_cleaner
I0103 03:52:14.145248       1 shared_informer.go:320] Caches are synced for token_cleaner
I0103 03:52:14.152862       1 controllermanager.go:797] "Started controller" controller="persistentvolume-protection-controller"
I0103 03:52:14.152978       1 pv_protection_controller.go:81] "Starting PV protection controller" logger="persistentvolume-protection-controller"
I0103 03:52:14.152988       1 shared_informer.go:313] Waiting for caches to sync for PV protection
I0103 03:52:14.158341       1 controllermanager.go:797] "Started controller" controller="endpointslice-mirroring-controller"
I0103 03:52:14.158369       1 endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller" logger="endpointslice-mirroring-controller"
I0103 03:52:14.158379       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice_mirroring
I0103 03:52:14.172897       1 controllermanager.go:797] "Started controller" controller="garbage-collector-controller"
I0103 03:52:14.172897       1 garbagecollector.go:146] "Starting controller" logger="garbage-collector-controller" controller="garbagecollector"
I0103 03:52:14.172977       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0103 03:52:14.173004       1 graph_builder.go:351] "Running" logger="garbage-collector-controller" component="GraphBuilder"
I0103 03:52:14.180646       1 controllermanager.go:797] "Started controller" controller="persistentvolumeclaim-protection-controller"
I0103 03:52:14.180688       1 pvc_protection_controller.go:105] "Starting PVC protection controller" logger="persistentvolumeclaim-protection-controller"
I0103 03:52:14.180696       1 shared_informer.go:313] Waiting for caches to sync for PVC protection
I0103 03:52:14.220425       1 shared_informer.go:320] Caches are synced for tokens
I0103 03:52:14.223421       1 controllermanager.go:797] "Started controller" controller="taint-eviction-controller"
I0103 03:52:14.223471       1 taint_eviction.go:281] "Starting" logger="taint-eviction-controller" controller="taint-eviction-controller"
I0103 03:52:14.223482       1 taint_eviction.go:287] "Sending events to api server" logger="taint-eviction-controller"
I0103 03:52:14.223492       1 shared_informer.go:313] Waiting for caches to sync for taint-eviction-controller
I0103 03:52:14.278506       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-serving"
I0103 03:52:14.278530       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 03:52:14.278541       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
I0103 03:52:14.278713       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-client"
I0103 03:52:14.278745       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-client
I0103 03:52:14.278735       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 03:52:14.278876       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kube-apiserver-client"
I0103 03:52:14.278903       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
I0103 03:52:14.278921       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 03:52:14.278982       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-signing-controller"
I0103 03:52:14.279034       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-legacy-unknown"
I0103 03:52:14.279041       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
I0103 03:52:14.279055       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
E0103 03:52:14.320640       1 core.go:274] "Failed to start cloud node lifecycle controller" err="no cloud provider provided" logger="cloud-node-lifecycle-controller"
I0103 03:52:14.320686       1 controllermanager.go:775] "Warning: skipping controller" controller="cloud-node-lifecycle-controller"
I0103 03:52:14.473821       1 range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses" logger="node-ipam-controller"
I0103 03:52:14.473855       1 controllermanager.go:797] "Started controller" controller="node-ipam-controller"
I0103 03:52:14.473941       1 node_ipam_controller.go:141] "Starting ipam controller" logger="node-ipam-controller"
I0103 03:52:14.473962       1 shared_informer.go:313] Waiting for caches to sync for node
I0103 03:52:14.623326       1 controllermanager.go:797] "Started controller" controller="root-ca-certificate-publisher-controller"
I0103 03:52:14.623352       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
I0103 03:52:14.623410       1 publisher.go:107] "Starting root CA cert publisher controller" logger="root-ca-certificate-publisher-controller"
I0103 03:52:14.623434       1 shared_informer.go:313] Waiting for caches to sync for crt configmap
I0103 03:52:14.772645       1 controllermanager.go:797] "Started controller" controller="statefulset-controller"
I0103 03:52:14.772736       1 stateful_set.go:166] "Starting stateful set controller" logger="statefulset-controller"
I0103 03:52:14.772759       1 shared_informer.go:313] Waiting for caches to sync for stateful set
I0103 03:52:14.923420       1 controllermanager.go:797] "Started controller" controller="ttl-controller"
I0103 03:52:14.923460       1 ttl_controller.go:127] "Starting TTL controller" logger="ttl-controller"
I0103 03:52:14.923471       1 shared_informer.go:313] Waiting for caches to sync for TTL
I0103 03:52:15.073322       1 controllermanager.go:797] "Started controller" controller="job-controller"
I0103 03:52:15.073384       1 job_controller.go:226] "Starting job controller" logger="job-controller"
I0103 03:52:15.073391       1 shared_informer.go:313] Waiting for caches to sync for job
I0103 03:52:15.223445       1 controllermanager.go:797] "Started controller" controller="deployment-controller"
I0103 03:52:15.223553       1 deployment_controller.go:173] "Starting controller" logger="deployment-controller" controller="deployment"
I0103 03:52:15.223576       1 shared_informer.go:313] Waiting for caches to sync for deployment
I0103 03:52:15.379571       1 controllermanager.go:797] "Started controller" controller="replicaset-controller"
I0103 03:52:15.379658       1 replica_set.go:217] "Starting controller" logger="replicaset-controller" name="replicaset"
I0103 03:52:15.379686       1 shared_informer.go:313] Waiting for caches to sync for ReplicaSet
I0103 03:52:15.525157       1 controllermanager.go:797] "Started controller" controller="clusterrole-aggregation-controller"
I0103 03:52:15.525200       1 clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller" logger="clusterrole-aggregation-controller"
I0103 03:52:15.525207       1 shared_informer.go:313] Waiting for caches to sync for ClusterRoleAggregator
I0103 03:52:15.673453       1 controllermanager.go:797] "Started controller" controller="pod-garbage-collector-controller"
I0103 03:52:15.673515       1 gc_controller.go:99] "Starting GC controller" logger="pod-garbage-collector-controller"
I0103 03:52:15.673523       1 shared_informer.go:313] Waiting for caches to sync for GC
I0103 03:52:15.829990       1 controllermanager.go:797] "Started controller" controller="serviceaccount-controller"
I0103 03:52:15.830049       1 serviceaccounts_controller.go:114] "Starting service account controller" logger="serviceaccount-controller"
I0103 03:52:15.830057       1 shared_informer.go:313] Waiting for caches to sync for service account
I0103 03:52:15.975454       1 controllermanager.go:797] "Started controller" controller="persistentvolume-attach-detach-controller"
I0103 03:52:15.975547       1 attach_detach_controller.go:338] "Starting attach detach controller" logger="persistentvolume-attach-detach-controller"
I0103 03:52:15.975558       1 shared_informer.go:313] Waiting for caches to sync for attach detach
I0103 03:52:16.125850       1 controllermanager.go:797] "Started controller" controller="ephemeral-volume-controller"
I0103 03:52:16.125905       1 controller.go:173] "Starting ephemeral volume controller" logger="ephemeral-volume-controller"
I0103 03:52:16.125912       1 shared_informer.go:313] Waiting for caches to sync for ephemeral
I0103 03:52:16.273532       1 controllermanager.go:797] "Started controller" controller="endpointslice-controller"
I0103 03:52:16.273565       1 endpointslice_controller.go:281] "Starting endpoint slice controller" logger="endpointslice-controller"
I0103 03:52:16.273574       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice
I0103 03:52:16.528733       1 controllermanager.go:797] "Started controller" controller="namespace-controller"
I0103 03:52:16.528792       1 namespace_controller.go:202] "Starting namespace controller" logger="namespace-controller"
I0103 03:52:16.528801       1 shared_informer.go:313] Waiting for caches to sync for namespace
I0103 03:52:16.570169       1 node_lifecycle_controller.go:430] "Controller will reconcile labels" logger="node-lifecycle-controller"
I0103 03:52:16.570304       1 controllermanager.go:797] "Started controller" controller="node-lifecycle-controller"
I0103 03:52:16.570398       1 node_lifecycle_controller.go:464] "Sending events to api server" logger="node-lifecycle-controller"
I0103 03:52:16.570443       1 node_lifecycle_controller.go:475] "Starting node controller" logger="node-lifecycle-controller"
I0103 03:52:16.570452       1 shared_informer.go:313] Waiting for caches to sync for taint
I0103 03:52:16.724959       1 controllermanager.go:797] "Started controller" controller="persistentvolume-expander-controller"
I0103 03:52:16.725039       1 expand_controller.go:328] "Starting expand controller" logger="persistentvolume-expander-controller"
I0103 03:52:16.725050       1 shared_informer.go:313] Waiting for caches to sync for expand
I0103 03:52:16.873733       1 controllermanager.go:797] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
I0103 03:52:16.873770       1 legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller" logger="legacy-serviceaccount-token-cleaner-controller"
I0103 03:52:16.873783       1 shared_informer.go:313] Waiting for caches to sync for legacy-service-account-token-cleaner
I0103 03:52:17.175350       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpoints"
I0103 03:52:17.175410       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="jobs.batch"
I0103 03:52:17.175434       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="limitranges"
I0103 03:52:17.175447       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="csistoragecapacities.storage.k8s.io"
I0103 03:52:17.175479       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="statefulsets.apps"
I0103 03:52:17.175524       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="ingresses.networking.k8s.io"
I0103 03:52:17.175533       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="horizontalpodautoscalers.autoscaling"
I0103 03:52:17.175547       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="leases.coordination.k8s.io"
I0103 03:52:17.175682       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="serviceaccounts"
I0103 03:52:17.175751       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="controllerrevisions.apps"
I0103 03:52:17.175783       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="replicasets.apps"
I0103 03:52:17.175843       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="poddisruptionbudgets.policy"
I0103 03:52:17.175855       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpointslices.discovery.k8s.io"
I0103 03:52:17.175867       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="deployments.apps"
I0103 03:52:17.175875       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="daemonsets.apps"
I0103 03:52:17.175925       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="cronjobs.batch"
I0103 03:52:17.175944       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="rolebindings.rbac.authorization.k8s.io"
I0103 03:52:17.175999       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="podtemplates"
I0103 03:52:17.176037       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="networkpolicies.networking.k8s.io"
I0103 03:52:17.176082       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="roles.rbac.authorization.k8s.io"
W0103 03:52:17.176114       1 shared_informer.go:597] resyncPeriod 13h37m1.861784578s is smaller than resyncCheckPeriod 23h10m53.417612206s and the informer has already started. Changing it to 23h10m53.417612206s
I0103 03:52:17.176147       1 controllermanager.go:797] "Started controller" controller="resourcequota-controller"
I0103 03:52:17.176320       1 resource_quota_controller.go:300] "Starting resource quota controller" logger="resourcequota-controller"
I0103 03:52:17.176346       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0103 03:52:17.176362       1 resource_quota_monitor.go:308] "QuotaMonitor running" logger="resourcequota-controller"
I0103 03:52:17.375885       1 controllermanager.go:797] "Started controller" controller="disruption-controller"
I0103 03:52:17.375940       1 disruption.go:452] "Sending events to api server." logger="disruption-controller"
I0103 03:52:17.375966       1 disruption.go:463] "Starting disruption controller" logger="disruption-controller"
I0103 03:52:17.375980       1 shared_informer.go:313] Waiting for caches to sync for disruption
I0103 03:52:17.522696       1 controllermanager.go:797] "Started controller" controller="replicationcontroller-controller"
I0103 03:52:17.522755       1 replica_set.go:217] "Starting controller" logger="replicationcontroller-controller" name="replicationcontroller"
I0103 03:52:17.522762       1 shared_informer.go:313] Waiting for caches to sync for ReplicationController
I0103 03:52:17.672803       1 controllermanager.go:797] "Started controller" controller="bootstrap-signer-controller"
I0103 03:52:17.672849       1 shared_informer.go:313] Waiting for caches to sync for bootstrap_signer
E0103 03:52:17.823036       1 core.go:105] "Failed to start service controller" err="WARNING: no cloud provider provided, services of type LoadBalancer will fail" logger="service-lb-controller"
I0103 03:52:17.823062       1 controllermanager.go:775] "Warning: skipping controller" controller="service-lb-controller"
I0103 03:52:17.823069       1 core.go:298] "Warning: configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes." logger="node-route-controller"
I0103 03:52:17.823072       1 controllermanager.go:775] "Warning: skipping controller" controller="node-route-controller"
I0103 03:52:17.972712       1 controllermanager.go:797] "Started controller" controller="persistentvolume-binder-controller"
I0103 03:52:17.972742       1 controllermanager.go:775] "Warning: skipping controller" controller="storage-version-migrator-controller"
I0103 03:52:17.972777       1 pv_controller_base.go:308] "Starting persistent volume controller" logger="persistentvolume-binder-controller"
I0103 03:52:17.972783       1 shared_informer.go:313] Waiting for caches to sync for persistent volume
I0103 03:52:18.123192       1 controllermanager.go:797] "Started controller" controller="endpoints-controller"
I0103 03:52:18.123304       1 endpoints_controller.go:182] "Starting endpoint controller" logger="endpoints-controller"
I0103 03:52:18.123326       1 shared_informer.go:313] Waiting for caches to sync for endpoint
I0103 03:52:18.170537       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0103 03:52:18.170568       1 cleaner.go:83] "Starting CSR cleaner controller" logger="certificatesigningrequest-cleaner-controller"
I0103 03:52:18.325109       1 controllermanager.go:797] "Started controller" controller="ttl-after-finished-controller"
I0103 03:52:18.325147       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
I0103 03:52:18.325153       1 ttlafterfinished_controller.go:112] "Starting TTL after finished controller" logger="ttl-after-finished-controller"
I0103 03:52:18.325253       1 shared_informer.go:313] Waiting for caches to sync for TTL after finished
I0103 03:52:18.520458       1 controllermanager.go:797] "Started controller" controller="validatingadmissionpolicy-status-controller"
I0103 03:52:18.520484       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
I0103 03:52:18.520520       1 shared_informer.go:313] Waiting for caches to sync for validatingadmissionpolicy-status
I0103 03:52:18.674111       1 controllermanager.go:797] "Started controller" controller="daemonset-controller"
I0103 03:52:18.674164       1 daemon_controller.go:294] "Starting daemon sets controller" logger="daemonset-controller"
I0103 03:52:18.674172       1 shared_informer.go:313] Waiting for caches to sync for daemon sets
I0103 03:52:18.823839       1 controllermanager.go:797] "Started controller" controller="cronjob-controller"
I0103 03:52:18.824001       1 cronjob_controllerv2.go:145] "Starting cronjob controller v2" logger="cronjob-controller"
I0103 03:52:18.824022       1 shared_informer.go:313] Waiting for caches to sync for cronjob
I0103 03:52:18.826457       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0103 03:52:18.837755       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0103 03:52:18.840432       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0103 03:52:18.853711       1 shared_informer.go:320] Caches are synced for PV protection
I0103 03:52:18.858957       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0103 03:52:18.872830       1 shared_informer.go:320] Caches are synced for stateful set
I0103 03:52:18.872928       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0103 03:52:18.874186       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0103 03:52:18.874202       1 shared_informer.go:320] Caches are synced for job
I0103 03:52:18.876090       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-control-plane\" does not exist"
I0103 03:52:18.878619       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0103 03:52:18.879808       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0103 03:52:18.879833       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0103 03:52:18.879864       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0103 03:52:18.879872       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0103 03:52:18.881004       1 shared_informer.go:320] Caches are synced for PVC protection
I0103 03:52:18.921429       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0103 03:52:18.923028       1 shared_informer.go:320] Caches are synced for ReplicationController
I0103 03:52:18.923414       1 shared_informer.go:320] Caches are synced for endpoint
I0103 03:52:18.923501       1 shared_informer.go:320] Caches are synced for crt configmap
I0103 03:52:18.923569       1 shared_informer.go:320] Caches are synced for TTL
I0103 03:52:18.923570       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0103 03:52:18.924126       1 shared_informer.go:320] Caches are synced for cronjob
I0103 03:52:18.925330       1 shared_informer.go:320] Caches are synced for TTL after finished
I0103 03:52:18.925353       1 shared_informer.go:320] Caches are synced for expand
I0103 03:52:18.925495       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0103 03:52:18.926206       1 shared_informer.go:320] Caches are synced for ephemeral
I0103 03:52:18.929291       1 shared_informer.go:320] Caches are synced for namespace
I0103 03:52:18.930339       1 shared_informer.go:320] Caches are synced for service account
I0103 03:52:18.934283       1 shared_informer.go:320] Caches are synced for HPA
I0103 03:52:18.971245       1 shared_informer.go:320] Caches are synced for taint
I0103 03:52:18.971300       1 node_lifecycle_controller.go:1232] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0103 03:52:18.971334       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-control-plane"
I0103 03:52:18.971369       1 node_lifecycle_controller.go:1036] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0103 03:52:18.973577       1 shared_informer.go:320] Caches are synced for persistent volume
I0103 03:52:18.973601       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0103 03:52:18.973627       1 shared_informer.go:320] Caches are synced for GC
I0103 03:52:18.974840       1 shared_informer.go:320] Caches are synced for daemon sets
I0103 03:52:18.974902       1 shared_informer.go:320] Caches are synced for node
I0103 03:52:18.974933       1 range_allocator.go:171] "Sending events to api server" logger="node-ipam-controller"
I0103 03:52:18.974946       1 range_allocator.go:177] "Starting range CIDR allocator" logger="node-ipam-controller"
I0103 03:52:18.974949       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0103 03:52:18.974952       1 shared_informer.go:320] Caches are synced for cidrallocator
I0103 03:52:18.975643       1 shared_informer.go:320] Caches are synced for attach detach
I0103 03:52:18.983929       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-control-plane" podCIDRs=["10.244.0.0/24"]
I0103 03:52:18.983946       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0103 03:52:18.983974       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0103 03:52:19.123768       1 shared_informer.go:320] Caches are synced for deployment
I0103 03:52:19.127407       1 shared_informer.go:320] Caches are synced for resource quota
I0103 03:52:19.176023       1 shared_informer.go:320] Caches are synced for disruption
I0103 03:52:19.176399       1 shared_informer.go:320] Caches are synced for resource quota
I0103 03:52:19.538574       1 shared_informer.go:320] Caches are synced for garbage collector
I0103 03:52:19.573721       1 shared_informer.go:320] Caches are synced for garbage collector
I0103 03:52:19.573748       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0103 03:52:19.682391       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0103 03:52:20.051403       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="111.111868ms"
I0103 03:52:20.055904       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="115.644754ms"
I0103 03:52:20.067886       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="16.436276ms"
I0103 03:52:20.067949       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="25.901µs"
I0103 03:52:20.073600       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="17.621625ms"
I0103 03:52:20.073720       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="39.502µs"
I0103 03:52:20.079486       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="59.003µs"
I0103 03:52:23.550284       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-worker2\" does not exist"
I0103 03:52:23.840739       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-worker2" podCIDRs=["10.244.1.0/24"]
I0103 03:52:23.840780       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:23.840829       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:23.972322       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-worker2"
I0103 03:52:24.007229       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-34-worker\" does not exist"
I0103 03:52:24.064778       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-34-worker" podCIDRs=["10.244.2.0/24"]
I0103 03:52:24.064824       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:24.064846       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:24.416448       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:24.615849       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:24.616644       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:25.928798       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:26.916686       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="781.986656ms"
I0103 03:52:27.177773       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="261.039267ms"
I0103 03:52:27.177826       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="21.401µs"
I0103 03:52:27.713530       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="706.115157ms"
I0103 03:52:27.976615       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="263.020449ms"
I0103 03:52:27.977017       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="23.601µs"
I0103 03:52:28.472829       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="39.701µs"
I0103 03:52:28.971659       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-34-worker"
I0103 03:52:33.291781       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0103 03:52:33.303121       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-control-plane"
I0103 03:52:33.313119       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="47.602µs"
I0103 03:52:33.313128       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="18.4µs"
I0103 03:52:33.332331       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="49.302µs"
I0103 03:52:33.354410       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="42.302µs"
I0103 03:52:33.367255       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="41.401µs"
I0103 03:52:33.382471       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="34.301µs"
I0103 03:52:33.971876       1 node_lifecycle_controller.go:1055] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0103 03:52:34.044025       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:44.012485       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:44.012517       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-34-worker"
I0103 03:52:44.583156       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-34-worker2"
I0103 03:52:44.583222       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:44.586178       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:52:44.785901       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="30.501µs"
I0103 03:52:44.786063       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:44.876593       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:45.044706       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="38.102µs"
I0103 03:52:47.215914       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="65.703µs"
I0103 03:52:47.702727       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="218.867842ms"
I0103 03:52:47.702835       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="42.602µs"
I0103 03:52:47.999863       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="296.925467ms"
I0103 03:52:47.999953       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="50.703µs"
I0103 03:52:49.150419       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker2"
I0103 03:52:50.243886       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="87.355009ms"
I0103 03:52:50.244174       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="42.302µs"
I0103 03:53:05.175818       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="37.301µs"
I0103 03:53:05.339584       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="35.101µs"
I0103 03:53:17.182675       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="34.202µs"
I0103 03:53:27.195535       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
I0103 03:53:31.192030       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="62.902µs"
I0103 03:53:50.530835       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="12.929027ms"
I0103 03:53:50.530934       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-687b65496d" duration="30.002µs"
I0103 03:53:56.061643       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="16.414669ms"
I0103 03:53:56.061715       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-68c4d85c7c" duration="29.301µs"
I0103 03:53:57.677762       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-34-worker"
==== END logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-34-control-plane ====
