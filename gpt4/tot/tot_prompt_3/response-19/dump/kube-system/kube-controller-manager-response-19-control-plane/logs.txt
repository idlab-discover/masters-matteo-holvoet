==== START logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-19-control-plane ====
I0108 06:02:41.213591       1 serving.go:386] Generated self-signed cert in-memory
I0108 06:02:41.732754       1 controllermanager.go:197] "Starting" version="v1.31.0"
I0108 06:02:41.732780       1 controllermanager.go:199] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0108 06:02:41.733754       1 dynamic_cafile_content.go:160] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I0108 06:02:41.733766       1 dynamic_cafile_content.go:160] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I0108 06:02:41.733834       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0108 06:02:41.734218       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0108 06:02:41.734455       1 leaderelection.go:254] attempting to acquire leader lease kube-system/kube-controller-manager...
E0108 06:02:43.353468       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
E0108 06:02:45.511647       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
I0108 06:02:48.796666       1 leaderelection.go:268] successfully acquired lease kube-system/kube-controller-manager
I0108 06:02:48.797271       1 event.go:389] "Event occurred" object="kube-system/kube-controller-manager" fieldPath="" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="response-19-control-plane_c497ee6c-8aee-4f99-b16a-3e947cb6480f became leader"
I0108 06:02:48.798689       1 controllermanager.go:797] "Started controller" controller="serviceaccount-token-controller"
I0108 06:02:48.798740       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0108 06:02:48.798722       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
I0108 06:02:48.798796       1 controllermanager.go:775] "Warning: skipping controller" controller="storage-version-migrator-controller"
I0108 06:02:48.892296       1 controllermanager.go:797] "Started controller" controller="serviceaccount-controller"
I0108 06:02:48.892446       1 serviceaccounts_controller.go:114] "Starting service account controller" logger="serviceaccount-controller"
I0108 06:02:48.892474       1 shared_informer.go:313] Waiting for caches to sync for service account
I0108 06:02:48.900598       1 shared_informer.go:320] Caches are synced for tokens
I0108 06:02:49.031908       1 garbagecollector.go:146] "Starting controller" logger="garbage-collector-controller" controller="garbagecollector"
I0108 06:02:49.031942       1 controllermanager.go:797] "Started controller" controller="garbage-collector-controller"
I0108 06:02:49.031956       1 graph_builder.go:351] "Running" logger="garbage-collector-controller" component="GraphBuilder"
I0108 06:02:49.031942       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0108 06:02:49.173383       1 controllermanager.go:797] "Started controller" controller="daemonset-controller"
I0108 06:02:49.173540       1 daemon_controller.go:294] "Starting daemon sets controller" logger="daemonset-controller"
I0108 06:02:49.173568       1 shared_informer.go:313] Waiting for caches to sync for daemon sets
I0108 06:02:49.348148       1 controllermanager.go:797] "Started controller" controller="horizontal-pod-autoscaler-controller"
I0108 06:02:49.348308       1 horizontal.go:201] "Starting HPA controller" logger="horizontal-pod-autoscaler-controller"
I0108 06:02:49.348340       1 shared_informer.go:313] Waiting for caches to sync for HPA
I0108 06:02:49.411513       1 controllermanager.go:797] "Started controller" controller="statefulset-controller"
I0108 06:02:49.411584       1 stateful_set.go:166] "Starting stateful set controller" logger="statefulset-controller"
I0108 06:02:49.411597       1 shared_informer.go:313] Waiting for caches to sync for stateful set
I0108 06:02:49.434706       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-serving"
I0108 06:02:49.434739       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
I0108 06:02:49.434756       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0108 06:02:49.435011       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-client"
I0108 06:02:49.435042       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-client
I0108 06:02:49.435055       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0108 06:02:49.435325       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kube-apiserver-client"
I0108 06:02:49.435353       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
I0108 06:02:49.435362       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-signing-controller"
I0108 06:02:49.435380       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-legacy-unknown"
I0108 06:02:49.435386       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
I0108 06:02:49.435396       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0108 06:02:49.435363       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0108 06:02:49.543387       1 controllermanager.go:797] "Started controller" controller="job-controller"
I0108 06:02:49.543783       1 job_controller.go:226] "Starting job controller" logger="job-controller"
I0108 06:02:49.543797       1 shared_informer.go:313] Waiting for caches to sync for job
I0108 06:02:49.650161       1 controllermanager.go:797] "Started controller" controller="cronjob-controller"
I0108 06:02:49.650354       1 cronjob_controllerv2.go:145] "Starting cronjob controller v2" logger="cronjob-controller"
I0108 06:02:49.650378       1 shared_informer.go:313] Waiting for caches to sync for cronjob
I0108 06:02:49.741252       1 range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses" logger="node-ipam-controller"
I0108 06:02:49.741331       1 controllermanager.go:797] "Started controller" controller="node-ipam-controller"
I0108 06:02:49.741512       1 node_ipam_controller.go:141] "Starting ipam controller" logger="node-ipam-controller"
I0108 06:02:49.741539       1 shared_informer.go:313] Waiting for caches to sync for node
E0108 06:02:49.743640       1 core.go:274] "Failed to start cloud node lifecycle controller" err="no cloud provider provided" logger="cloud-node-lifecycle-controller"
I0108 06:02:49.743672       1 controllermanager.go:775] "Warning: skipping controller" controller="cloud-node-lifecycle-controller"
I0108 06:02:49.806635       1 controllermanager.go:797] "Started controller" controller="persistentvolume-binder-controller"
I0108 06:02:49.806822       1 pv_controller_base.go:308] "Starting persistent volume controller" logger="persistentvolume-binder-controller"
I0108 06:02:49.806853       1 shared_informer.go:313] Waiting for caches to sync for persistent volume
I0108 06:02:49.824477       1 controllermanager.go:797] "Started controller" controller="endpoints-controller"
I0108 06:02:49.824626       1 endpoints_controller.go:182] "Starting endpoint controller" logger="endpoints-controller"
I0108 06:02:49.824655       1 shared_informer.go:313] Waiting for caches to sync for endpoint
I0108 06:02:49.846556       1 controllermanager.go:797] "Started controller" controller="endpointslice-controller"
I0108 06:02:49.846697       1 endpointslice_controller.go:281] "Starting endpoint slice controller" logger="endpointslice-controller"
I0108 06:02:49.846732       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice
I0108 06:02:49.877231       1 controllermanager.go:797] "Started controller" controller="ephemeral-volume-controller"
I0108 06:02:49.877264       1 controller.go:173] "Starting ephemeral volume controller" logger="ephemeral-volume-controller"
I0108 06:02:49.877267       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
I0108 06:02:49.877280       1 shared_informer.go:313] Waiting for caches to sync for ephemeral
I0108 06:02:50.072784       1 controllermanager.go:797] "Started controller" controller="validatingadmissionpolicy-status-controller"
I0108 06:02:50.072894       1 shared_informer.go:313] Waiting for caches to sync for validatingadmissionpolicy-status
I0108 06:02:50.222009       1 controllermanager.go:797] "Started controller" controller="persistentvolumeclaim-protection-controller"
I0108 06:02:50.222055       1 pvc_protection_controller.go:105] "Starting PVC protection controller" logger="persistentvolumeclaim-protection-controller"
I0108 06:02:50.222068       1 shared_informer.go:313] Waiting for caches to sync for PVC protection
I0108 06:02:50.404014       1 controllermanager.go:797] "Started controller" controller="root-ca-certificate-publisher-controller"
I0108 06:02:50.404193       1 publisher.go:107] "Starting root CA cert publisher controller" logger="root-ca-certificate-publisher-controller"
I0108 06:02:50.404209       1 shared_informer.go:313] Waiting for caches to sync for crt configmap
I0108 06:02:50.585181       1 controllermanager.go:797] "Started controller" controller="replicationcontroller-controller"
I0108 06:02:50.585277       1 replica_set.go:217] "Starting controller" logger="replicationcontroller-controller" name="replicationcontroller"
I0108 06:02:50.585323       1 shared_informer.go:313] Waiting for caches to sync for ReplicationController
I0108 06:02:50.688851       1 controllermanager.go:797] "Started controller" controller="deployment-controller"
I0108 06:02:50.688959       1 deployment_controller.go:173] "Starting controller" logger="deployment-controller" controller="deployment"
I0108 06:02:50.688974       1 shared_informer.go:313] Waiting for caches to sync for deployment
I0108 06:02:50.839357       1 controllermanager.go:797] "Started controller" controller="disruption-controller"
I0108 06:02:50.839445       1 disruption.go:452] "Sending events to api server." logger="disruption-controller"
I0108 06:02:50.839486       1 disruption.go:463] "Starting disruption controller" logger="disruption-controller"
I0108 06:02:50.839524       1 shared_informer.go:313] Waiting for caches to sync for disruption
I0108 06:02:50.961958       1 controllermanager.go:797] "Started controller" controller="bootstrap-signer-controller"
I0108 06:02:50.962079       1 shared_informer.go:313] Waiting for caches to sync for bootstrap_signer
E0108 06:02:51.134653       1 core.go:105] "Failed to start service controller" err="WARNING: no cloud provider provided, services of type LoadBalancer will fail" logger="service-lb-controller"
I0108 06:02:51.134674       1 controllermanager.go:775] "Warning: skipping controller" controller="service-lb-controller"
I0108 06:02:51.149927       1 controllermanager.go:797] "Started controller" controller="taint-eviction-controller"
I0108 06:02:51.150238       1 taint_eviction.go:281] "Starting" logger="taint-eviction-controller" controller="taint-eviction-controller"
I0108 06:02:51.150731       1 taint_eviction.go:287] "Sending events to api server" logger="taint-eviction-controller"
I0108 06:02:51.150761       1 shared_informer.go:313] Waiting for caches to sync for taint-eviction-controller
I0108 06:02:51.428824       1 controllermanager.go:797] "Started controller" controller="endpointslice-mirroring-controller"
I0108 06:02:51.428941       1 endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller" logger="endpointslice-mirroring-controller"
I0108 06:02:51.429294       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice_mirroring
I0108 06:02:51.478601       1 controllermanager.go:797] "Started controller" controller="replicaset-controller"
I0108 06:02:51.478675       1 replica_set.go:217] "Starting controller" logger="replicaset-controller" name="replicaset"
I0108 06:02:51.478689       1 shared_informer.go:313] Waiting for caches to sync for ReplicaSet
I0108 06:02:51.608439       1 controllermanager.go:797] "Started controller" controller="token-cleaner-controller"
I0108 06:02:51.608516       1 tokencleaner.go:117] "Starting token cleaner controller" logger="token-cleaner-controller"
I0108 06:02:51.608612       1 shared_informer.go:313] Waiting for caches to sync for token_cleaner
I0108 06:02:51.608636       1 shared_informer.go:320] Caches are synced for token_cleaner
I0108 06:02:51.804908       1 controllermanager.go:797] "Started controller" controller="persistentvolume-attach-detach-controller"
I0108 06:02:51.805262       1 attach_detach_controller.go:338] "Starting attach detach controller" logger="persistentvolume-attach-detach-controller"
I0108 06:02:51.805294       1 shared_informer.go:313] Waiting for caches to sync for attach detach
I0108 06:02:52.012145       1 controllermanager.go:797] "Started controller" controller="namespace-controller"
I0108 06:02:52.012192       1 namespace_controller.go:202] "Starting namespace controller" logger="namespace-controller"
I0108 06:02:52.012363       1 shared_informer.go:313] Waiting for caches to sync for namespace
I0108 06:02:52.049875       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-approving-controller"
I0108 06:02:52.049936       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-approving-controller" name="csrapproving"
I0108 06:02:52.049948       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrapproving
I0108 06:02:52.099675       1 node_lifecycle_controller.go:430] "Controller will reconcile labels" logger="node-lifecycle-controller"
I0108 06:02:52.099743       1 controllermanager.go:797] "Started controller" controller="node-lifecycle-controller"
I0108 06:02:52.099852       1 node_lifecycle_controller.go:464] "Sending events to api server" logger="node-lifecycle-controller"
I0108 06:02:52.099884       1 node_lifecycle_controller.go:475] "Starting node controller" logger="node-lifecycle-controller"
I0108 06:02:52.099893       1 shared_informer.go:313] Waiting for caches to sync for taint
I0108 06:02:52.259889       1 controllermanager.go:797] "Started controller" controller="ttl-after-finished-controller"
I0108 06:02:52.259922       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
I0108 06:02:52.259973       1 ttlafterfinished_controller.go:112] "Starting TTL after finished controller" logger="ttl-after-finished-controller"
I0108 06:02:52.259987       1 shared_informer.go:313] Waiting for caches to sync for TTL after finished
I0108 06:02:52.410727       1 controllermanager.go:797] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
I0108 06:02:52.410772       1 legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller" logger="legacy-serviceaccount-token-cleaner-controller"
I0108 06:02:52.410779       1 shared_informer.go:313] Waiting for caches to sync for legacy-service-account-token-cleaner
I0108 06:02:52.554109       1 controllermanager.go:797] "Started controller" controller="pod-garbage-collector-controller"
I0108 06:02:52.554200       1 gc_controller.go:99] "Starting GC controller" logger="pod-garbage-collector-controller"
I0108 06:02:52.554209       1 shared_informer.go:313] Waiting for caches to sync for GC
I0108 06:02:52.853746       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="leases.coordination.k8s.io"
I0108 06:02:52.853790       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="statefulsets.apps"
I0108 06:02:52.853826       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="roles.rbac.authorization.k8s.io"
I0108 06:02:52.853850       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="csistoragecapacities.storage.k8s.io"
I0108 06:02:52.853886       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="poddisruptionbudgets.policy"
I0108 06:02:52.853925       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpoints"
I0108 06:02:52.853955       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="cronjobs.batch"
I0108 06:02:52.853992       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="deployments.apps"
I0108 06:02:52.854021       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpointslices.discovery.k8s.io"
W0108 06:02:52.854071       1 shared_informer.go:597] resyncPeriod 17h46m37.303545431s is smaller than resyncCheckPeriod 20h23m37.56800787s and the informer has already started. Changing it to 20h23m37.56800787s
I0108 06:02:52.854120       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="serviceaccounts"
I0108 06:02:52.854160       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="replicasets.apps"
I0108 06:02:52.854217       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="controllerrevisions.apps"
I0108 06:02:52.854261       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="horizontalpodautoscalers.autoscaling"
I0108 06:02:52.854280       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="limitranges"
W0108 06:02:52.854301       1 shared_informer.go:597] resyncPeriod 17h10m56.918770825s is smaller than resyncCheckPeriod 20h23m37.56800787s and the informer has already started. Changing it to 20h23m37.56800787s
I0108 06:02:52.854383       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="networkpolicies.networking.k8s.io"
I0108 06:02:52.854436       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="rolebindings.rbac.authorization.k8s.io"
I0108 06:02:52.854476       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="daemonsets.apps"
I0108 06:02:52.854499       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="jobs.batch"
I0108 06:02:52.854522       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="ingresses.networking.k8s.io"
I0108 06:02:52.854883       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="podtemplates"
I0108 06:02:52.854930       1 controllermanager.go:797] "Started controller" controller="resourcequota-controller"
I0108 06:02:52.855100       1 resource_quota_controller.go:300] "Starting resource quota controller" logger="resourcequota-controller"
I0108 06:02:52.855126       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0108 06:02:52.855143       1 resource_quota_monitor.go:308] "QuotaMonitor running" logger="resourcequota-controller"
I0108 06:02:52.899667       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0108 06:02:52.899725       1 cleaner.go:83] "Starting CSR cleaner controller" logger="certificatesigningrequest-cleaner-controller"
I0108 06:02:53.059747       1 controllermanager.go:797] "Started controller" controller="ttl-controller"
I0108 06:02:53.059812       1 ttl_controller.go:127] "Starting TTL controller" logger="ttl-controller"
I0108 06:02:53.059821       1 shared_informer.go:313] Waiting for caches to sync for TTL
I0108 06:02:53.203435       1 controllermanager.go:797] "Started controller" controller="clusterrole-aggregation-controller"
I0108 06:02:53.203491       1 clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller" logger="clusterrole-aggregation-controller"
I0108 06:02:53.203502       1 shared_informer.go:313] Waiting for caches to sync for ClusterRoleAggregator
I0108 06:02:53.355123       1 controllermanager.go:797] "Started controller" controller="persistentvolume-protection-controller"
I0108 06:02:53.355160       1 core.go:298] "Warning: configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes." logger="node-route-controller"
I0108 06:02:53.355168       1 controllermanager.go:775] "Warning: skipping controller" controller="node-route-controller"
I0108 06:02:53.355213       1 pv_protection_controller.go:81] "Starting PV protection controller" logger="persistentvolume-protection-controller"
I0108 06:02:53.355243       1 shared_informer.go:313] Waiting for caches to sync for PV protection
I0108 06:02:53.517478       1 controllermanager.go:797] "Started controller" controller="persistentvolume-expander-controller"
I0108 06:02:53.518318       1 expand_controller.go:328] "Starting expand controller" logger="persistentvolume-expander-controller"
I0108 06:02:53.518339       1 shared_informer.go:313] Waiting for caches to sync for expand
I0108 06:02:53.519987       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0108 06:02:53.536441       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-19-control-plane\" does not exist"
I0108 06:02:53.536483       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0108 06:02:53.536502       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0108 06:02:53.536526       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0108 06:02:53.536546       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0108 06:02:53.541809       1 shared_informer.go:320] Caches are synced for node
I0108 06:02:53.541977       1 range_allocator.go:171] "Sending events to api server" logger="node-ipam-controller"
I0108 06:02:53.542027       1 range_allocator.go:177] "Starting range CIDR allocator" logger="node-ipam-controller"
I0108 06:02:53.542111       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0108 06:02:53.542140       1 shared_informer.go:320] Caches are synced for cidrallocator
I0108 06:02:53.544765       1 shared_informer.go:320] Caches are synced for job
I0108 06:02:53.546246       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0108 06:02:53.546842       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0108 06:02:53.548454       1 shared_informer.go:320] Caches are synced for HPA
I0108 06:02:53.550057       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0108 06:02:53.551186       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0108 06:02:53.554453       1 shared_informer.go:320] Caches are synced for GC
I0108 06:02:53.559918       1 shared_informer.go:320] Caches are synced for TTL
I0108 06:02:53.560067       1 shared_informer.go:320] Caches are synced for TTL after finished
I0108 06:02:53.563321       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0108 06:02:53.574096       1 shared_informer.go:320] Caches are synced for daemon sets
I0108 06:02:53.581523       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0108 06:02:53.582562       1 shared_informer.go:320] Caches are synced for ephemeral
I0108 06:02:53.589770       1 shared_informer.go:320] Caches are synced for deployment
I0108 06:02:53.592592       1 shared_informer.go:320] Caches are synced for service account
I0108 06:02:53.600279       1 shared_informer.go:320] Caches are synced for taint
I0108 06:02:53.600360       1 node_lifecycle_controller.go:1232] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0108 06:02:53.600420       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-19-control-plane"
I0108 06:02:53.600487       1 node_lifecycle_controller.go:1036] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0108 06:02:53.603569       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0108 06:02:53.604855       1 shared_informer.go:320] Caches are synced for crt configmap
I0108 06:02:53.606015       1 shared_informer.go:320] Caches are synced for attach detach
I0108 06:02:53.606731       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-19-control-plane" podCIDRs=["10.244.0.0/24"]
I0108 06:02:53.606762       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-control-plane"
I0108 06:02:53.606876       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-control-plane"
I0108 06:02:53.606941       1 shared_informer.go:320] Caches are synced for persistent volume
I0108 06:02:53.611147       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0108 06:02:53.612401       1 shared_informer.go:320] Caches are synced for stateful set
I0108 06:02:53.613476       1 shared_informer.go:320] Caches are synced for namespace
I0108 06:02:53.619297       1 shared_informer.go:320] Caches are synced for expand
I0108 06:02:53.622297       1 shared_informer.go:320] Caches are synced for PVC protection
I0108 06:02:53.625631       1 shared_informer.go:320] Caches are synced for endpoint
I0108 06:02:53.629885       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0108 06:02:53.640419       1 shared_informer.go:320] Caches are synced for disruption
I0108 06:02:53.656123       1 shared_informer.go:320] Caches are synced for PV protection
I0108 06:02:53.685834       1 shared_informer.go:320] Caches are synced for ReplicationController
I0108 06:02:53.750589       1 shared_informer.go:320] Caches are synced for cronjob
I0108 06:02:53.755983       1 shared_informer.go:320] Caches are synced for resource quota
I0108 06:02:53.773309       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0108 06:02:53.820467       1 shared_informer.go:320] Caches are synced for resource quota
I0108 06:02:54.224086       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-control-plane"
I0108 06:02:54.246961       1 shared_informer.go:320] Caches are synced for garbage collector
I0108 06:02:54.319551       1 shared_informer.go:320] Caches are synced for garbage collector
I0108 06:02:54.319579       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0108 06:02:54.909176       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="452.263881ms"
I0108 06:02:55.014069       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="558.33191ms"
I0108 06:02:55.024565       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="115.335581ms"
I0108 06:02:55.024652       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="24.8µs"
I0108 06:02:55.049312       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="35.191937ms"
I0108 06:02:55.049392       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="44.301µs"
I0108 06:02:55.049454       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="24.901µs"
I0108 06:02:58.242109       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-19-worker2\" does not exist"
I0108 06:02:58.278357       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-19-worker2" podCIDRs=["10.244.1.0/24"]
I0108 06:02:58.278393       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:02:58.279482       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:02:58.301971       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:02:58.402446       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:02:58.476936       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-19-worker\" does not exist"
I0108 06:02:58.513622       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-19-worker" podCIDRs=["10.244.2.0/24"]
I0108 06:02:58.513648       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:02:58.513733       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:02:58.549551       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:02:58.601578       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-19-worker"
I0108 06:02:58.601584       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-19-worker2"
I0108 06:02:59.379833       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:02:59.881630       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="95.961945ms"
I0108 06:02:59.992294       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="110.619502ms"
I0108 06:02:59.992359       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="30.601µs"
I0108 06:03:00.000147       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="78.871497ms"
I0108 06:03:00.105110       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="104.908385ms"
I0108 06:03:00.105209       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="32.001µs"
I0108 06:03:07.481627       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-control-plane"
I0108 06:03:07.739065       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-control-plane"
I0108 06:03:07.794672       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="30.901µs"
I0108 06:03:07.871724       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="45.901µs"
I0108 06:03:07.871802       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="27.601µs"
I0108 06:03:07.937963       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="37.701µs"
I0108 06:03:08.035439       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="62.002µs"
I0108 06:03:08.074782       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="34.601µs"
I0108 06:03:08.419497       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:03:08.601492       1 node_lifecycle_controller.go:1055] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0108 06:03:08.713521       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:03:15.452981       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-19-worker2"
I0108 06:03:15.453057       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:03:15.466499       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:03:16.308289       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="54.002µs"
I0108 06:03:16.341732       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:03:16.341956       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-19-worker2"
I0108 06:03:16.389198       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker"
I0108 06:03:16.446931       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="43.314894ms"
I0108 06:03:16.469456       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="22.058912ms"
I0108 06:03:16.469661       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="143.205µs"
I0108 06:03:17.306579       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="17.279235ms"
I0108 06:03:17.306646       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="22.501µs"
I0108 06:03:25.532138       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="40.402µs"
I0108 06:03:25.564896       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="39.901µs"
I0108 06:03:25.612562       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="40.501µs"
I0108 06:03:25.644903       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="50.102µs"
I0108 06:03:46.278811       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/wordpress-9f449766f" duration="73.003µs"
I0108 06:03:59.074359       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
I0108 06:04:01.315689       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="142.105µs"
I0108 06:04:21.239809       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="127.45535ms"
I0108 06:04:21.239880       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="default/mysql-67df677fb" duration="22.501µs"
I0108 06:04:29.371691       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-19-worker2"
==== END logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-19-control-plane ====
