==== START logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-25-control-plane ====
I0103 23:33:13.589628       1 serving.go:386] Generated self-signed cert in-memory
I0103 23:33:13.744031       1 controllermanager.go:197] "Starting" version="v1.31.0"
I0103 23:33:13.744083       1 controllermanager.go:199] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0103 23:33:13.745130       1 dynamic_cafile_content.go:160] "Starting controller" name="request-header::/etc/kubernetes/pki/front-proxy-ca.crt"
I0103 23:33:13.745178       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
I0103 23:33:13.745131       1 dynamic_cafile_content.go:160] "Starting controller" name="client-ca-bundle::/etc/kubernetes/pki/ca.crt"
I0103 23:33:13.745245       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
I0103 23:33:13.745284       1 leaderelection.go:254] attempting to acquire leader lease kube-system/kube-controller-manager...
E0103 23:33:15.765117       1 leaderelection.go:436] error retrieving resource lock kube-system/kube-controller-manager: leases.coordination.k8s.io "kube-controller-manager" is forbidden: User "system:kube-controller-manager" cannot get resource "leases" in API group "coordination.k8s.io" in the namespace "kube-system"
I0103 23:33:19.745880       1 leaderelection.go:268] successfully acquired lease kube-system/kube-controller-manager
I0103 23:33:19.746131       1 event.go:389] "Event occurred" object="kube-system/kube-controller-manager" fieldPath="" kind="Lease" apiVersion="coordination.k8s.io/v1" type="Normal" reason="LeaderElection" message="response-25-control-plane_4b06bd4f-6ea8-460d-8579-3ad344a564e7 became leader"
I0103 23:33:21.750641       1 controllermanager.go:797] "Started controller" controller="serviceaccount-token-controller"
I0103 23:33:21.750720       1 core.go:298] "Warning: configure-cloud-routes is set, but no cloud provider specified. Will not configure cloud provider routes." logger="node-route-controller"
I0103 23:33:21.750730       1 controllermanager.go:775] "Warning: skipping controller" controller="node-route-controller"
I0103 23:33:21.750938       1 shared_informer.go:313] Waiting for caches to sync for tokens
I0103 23:33:21.851992       1 shared_informer.go:320] Caches are synced for tokens
I0103 23:33:21.884026       1 controllermanager.go:797] "Started controller" controller="persistentvolume-protection-controller"
I0103 23:33:21.884110       1 pv_protection_controller.go:81] "Starting PV protection controller" logger="persistentvolume-protection-controller"
I0103 23:33:21.884138       1 shared_informer.go:313] Waiting for caches to sync for PV protection
I0103 23:33:22.066239       1 controllermanager.go:797] "Started controller" controller="validatingadmissionpolicy-status-controller"
I0103 23:33:22.066282       1 shared_informer.go:313] Waiting for caches to sync for validatingadmissionpolicy-status
I0103 23:33:22.095776       1 controllermanager.go:797] "Started controller" controller="endpointslice-controller"
I0103 23:33:22.095898       1 endpointslice_controller.go:281] "Starting endpoint slice controller" logger="endpointslice-controller"
I0103 23:33:22.095933       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice
I0103 23:33:22.174520       1 controllermanager.go:797] "Started controller" controller="job-controller"
I0103 23:33:22.174654       1 job_controller.go:226] "Starting job controller" logger="job-controller"
I0103 23:33:22.174716       1 shared_informer.go:313] Waiting for caches to sync for job
I0103 23:33:22.204869       1 controllermanager.go:797] "Started controller" controller="horizontal-pod-autoscaler-controller"
I0103 23:33:22.204962       1 horizontal.go:201] "Starting HPA controller" logger="horizontal-pod-autoscaler-controller"
I0103 23:33:22.204993       1 shared_informer.go:313] Waiting for caches to sync for HPA
I0103 23:33:22.232370       1 controllermanager.go:797] "Started controller" controller="token-cleaner-controller"
I0103 23:33:22.232545       1 tokencleaner.go:117] "Starting token cleaner controller" logger="token-cleaner-controller"
I0103 23:33:22.232555       1 shared_informer.go:313] Waiting for caches to sync for token_cleaner
I0103 23:33:22.232561       1 shared_informer.go:320] Caches are synced for token_cleaner
I0103 23:33:22.247767       1 controllermanager.go:797] "Started controller" controller="persistentvolume-expander-controller"
I0103 23:33:22.247936       1 expand_controller.go:328] "Starting expand controller" logger="persistentvolume-expander-controller"
I0103 23:33:22.247959       1 shared_informer.go:313] Waiting for caches to sync for expand
I0103 23:33:22.482363       1 controllermanager.go:797] "Started controller" controller="taint-eviction-controller"
I0103 23:33:22.482496       1 taint_eviction.go:281] "Starting" logger="taint-eviction-controller" controller="taint-eviction-controller"
I0103 23:33:22.482580       1 taint_eviction.go:287] "Sending events to api server" logger="taint-eviction-controller"
I0103 23:33:22.482599       1 shared_informer.go:313] Waiting for caches to sync for taint-eviction-controller
I0103 23:33:22.509666       1 controllermanager.go:797] "Started controller" controller="serviceaccount-controller"
I0103 23:33:22.509785       1 serviceaccounts_controller.go:114] "Starting service account controller" logger="serviceaccount-controller"
I0103 23:33:22.509809       1 shared_informer.go:313] Waiting for caches to sync for service account
I0103 23:33:22.577798       1 controllermanager.go:797] "Started controller" controller="daemonset-controller"
I0103 23:33:22.577851       1 daemon_controller.go:294] "Starting daemon sets controller" logger="daemonset-controller"
I0103 23:33:22.577862       1 shared_informer.go:313] Waiting for caches to sync for daemon sets
I0103 23:33:22.597721       1 controllermanager.go:797] "Started controller" controller="ttl-controller"
I0103 23:33:22.597834       1 ttl_controller.go:127] "Starting TTL controller" logger="ttl-controller"
I0103 23:33:22.597863       1 shared_informer.go:313] Waiting for caches to sync for TTL
I0103 23:33:22.743592       1 controllermanager.go:797] "Started controller" controller="persistentvolume-attach-detach-controller"
I0103 23:33:22.743756       1 attach_detach_controller.go:338] "Starting attach detach controller" logger="persistentvolume-attach-detach-controller"
I0103 23:33:22.743801       1 shared_informer.go:313] Waiting for caches to sync for attach detach
I0103 23:33:22.835901       1 controllermanager.go:797] "Started controller" controller="bootstrap-signer-controller"
I0103 23:33:22.836016       1 shared_informer.go:313] Waiting for caches to sync for bootstrap_signer
I0103 23:33:23.000953       1 range_allocator.go:112] "No Secondary Service CIDR provided. Skipping filtering out secondary service addresses" logger="node-ipam-controller"
I0103 23:33:23.001013       1 controllermanager.go:797] "Started controller" controller="node-ipam-controller"
I0103 23:33:23.001216       1 node_ipam_controller.go:141] "Starting ipam controller" logger="node-ipam-controller"
I0103 23:33:23.001230       1 shared_informer.go:313] Waiting for caches to sync for node
E0103 23:33:23.129710       1 core.go:105] "Failed to start service controller" err="WARNING: no cloud provider provided, services of type LoadBalancer will fail" logger="service-lb-controller"
I0103 23:33:23.129800       1 controllermanager.go:775] "Warning: skipping controller" controller="service-lb-controller"
I0103 23:33:23.165494       1 controllermanager.go:797] "Started controller" controller="ttl-after-finished-controller"
I0103 23:33:23.165585       1 ttlafterfinished_controller.go:112] "Starting TTL after finished controller" logger="ttl-after-finished-controller"
I0103 23:33:23.165617       1 shared_informer.go:313] Waiting for caches to sync for TTL after finished
I0103 23:33:23.297659       1 controllermanager.go:797] "Started controller" controller="replicationcontroller-controller"
I0103 23:33:23.297733       1 replica_set.go:217] "Starting controller" logger="replicationcontroller-controller" name="replicationcontroller"
I0103 23:33:23.297962       1 shared_informer.go:313] Waiting for caches to sync for ReplicationController
I0103 23:33:23.430206       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="daemonsets.apps"
I0103 23:33:23.430324       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="horizontalpodautoscalers.autoscaling"
I0103 23:33:23.430382       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="csistoragecapacities.storage.k8s.io"
I0103 23:33:23.430424       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="podtemplates"
I0103 23:33:23.430466       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="deployments.apps"
I0103 23:33:23.430764       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="statefulsets.apps"
I0103 23:33:23.430823       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="roles.rbac.authorization.k8s.io"
I0103 23:33:23.430867       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="controllerrevisions.apps"
I0103 23:33:23.430881       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="leases.coordination.k8s.io"
W0103 23:33:23.430895       1 shared_informer.go:597] resyncPeriod 18h12m3.958959586s is smaller than resyncCheckPeriod 18h48m41.742861265s and the informer has already started. Changing it to 18h48m41.742861265s
I0103 23:33:23.430928       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="serviceaccounts"
I0103 23:33:23.430964       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="poddisruptionbudgets.policy"
I0103 23:33:23.431037       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="cronjobs.batch"
I0103 23:33:23.431083       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpointslices.discovery.k8s.io"
I0103 23:33:23.431117       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="limitranges"
W0103 23:33:23.431129       1 shared_informer.go:597] resyncPeriod 17h2m28.213640327s is smaller than resyncCheckPeriod 18h48m41.742861265s and the informer has already started. Changing it to 18h48m41.742861265s
I0103 23:33:23.431156       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="replicasets.apps"
I0103 23:33:23.431170       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="jobs.batch"
I0103 23:33:23.431196       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="ingresses.networking.k8s.io"
I0103 23:33:23.431214       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="networkpolicies.networking.k8s.io"
I0103 23:33:23.431227       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="rolebindings.rbac.authorization.k8s.io"
I0103 23:33:23.431241       1 resource_quota_monitor.go:227] "QuotaMonitor created object count evaluator" logger="resourcequota-controller" resource="endpoints"
I0103 23:33:23.431254       1 controllermanager.go:797] "Started controller" controller="resourcequota-controller"
I0103 23:33:23.431409       1 resource_quota_controller.go:300] "Starting resource quota controller" logger="resourcequota-controller"
I0103 23:33:23.431436       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0103 23:33:23.431592       1 resource_quota_monitor.go:308] "QuotaMonitor running" logger="resourcequota-controller"
I0103 23:33:23.596690       1 controllermanager.go:797] "Started controller" controller="namespace-controller"
I0103 23:33:23.596959       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="resourceclaim-controller" requiredFeatureGates=["DynamicResourceAllocation"]
I0103 23:33:23.596936       1 namespace_controller.go:202] "Starting namespace controller" logger="namespace-controller"
I0103 23:33:23.597261       1 shared_informer.go:313] Waiting for caches to sync for namespace
I0103 23:33:23.790183       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-serving"
I0103 23:33:23.790205       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-serving
I0103 23:33:23.790225       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 23:33:23.790452       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kubelet-client"
I0103 23:33:23.790587       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kubelet-client
I0103 23:33:23.790642       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 23:33:23.790833       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-signing-controller"
I0103 23:33:23.790858       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-kube-apiserver-client"
I0103 23:33:23.790868       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-kube-apiserver-client
I0103 23:33:23.790896       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 23:33:23.791041       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-signing-controller" name="csrsigning-legacy-unknown"
I0103 23:33:23.791072       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrsigning-legacy-unknown
I0103 23:33:23.791096       1 dynamic_serving_content.go:135] "Starting controller" name="csr-controller::/etc/kubernetes/pki/ca.crt::/etc/kubernetes/pki/ca.key"
I0103 23:33:24.050709       1 controllermanager.go:797] "Started controller" controller="root-ca-certificate-publisher-controller"
I0103 23:33:24.050740       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="storageversion-garbage-collector-controller" requiredFeatureGates=["APIServerIdentity","StorageVersionAPI"]
I0103 23:33:24.050754       1 controllermanager.go:775] "Warning: skipping controller" controller="storage-version-migrator-controller"
I0103 23:33:24.050758       1 controllermanager.go:749] "Controller is disabled by a feature gate" controller="service-cidr-controller" requiredFeatureGates=["MultiCIDRServiceAllocator"]
I0103 23:33:24.050743       1 publisher.go:107] "Starting root CA cert publisher controller" logger="root-ca-certificate-publisher-controller"
I0103 23:33:24.050872       1 shared_informer.go:313] Waiting for caches to sync for crt configmap
I0103 23:33:24.094589       1 controllermanager.go:797] "Started controller" controller="endpoints-controller"
I0103 23:33:24.094631       1 endpoints_controller.go:182] "Starting endpoint controller" logger="endpoints-controller"
I0103 23:33:24.094642       1 shared_informer.go:313] Waiting for caches to sync for endpoint
I0103 23:33:24.290102       1 controllermanager.go:797] "Started controller" controller="garbage-collector-controller"
I0103 23:33:24.290255       1 garbagecollector.go:146] "Starting controller" logger="garbage-collector-controller" controller="garbagecollector"
I0103 23:33:24.290303       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0103 23:33:24.290321       1 graph_builder.go:351] "Running" logger="garbage-collector-controller" component="GraphBuilder"
I0103 23:33:24.576959       1 controllermanager.go:797] "Started controller" controller="cronjob-controller"
I0103 23:33:24.577031       1 cronjob_controllerv2.go:145] "Starting cronjob controller v2" logger="cronjob-controller"
I0103 23:33:24.577038       1 shared_informer.go:313] Waiting for caches to sync for cronjob
I0103 23:33:24.765036       1 controllermanager.go:797] "Started controller" controller="clusterrole-aggregation-controller"
I0103 23:33:24.765094       1 clusterroleaggregation_controller.go:194] "Starting ClusterRoleAggregator controller" logger="clusterrole-aggregation-controller"
I0103 23:33:24.765108       1 shared_informer.go:313] Waiting for caches to sync for ClusterRoleAggregator
I0103 23:33:24.873061       1 controllermanager.go:797] "Started controller" controller="deployment-controller"
I0103 23:33:24.873174       1 deployment_controller.go:173] "Starting controller" logger="deployment-controller" controller="deployment"
I0103 23:33:24.873194       1 shared_informer.go:313] Waiting for caches to sync for deployment
I0103 23:33:25.039452       1 controllermanager.go:797] "Started controller" controller="replicaset-controller"
I0103 23:33:25.039644       1 replica_set.go:217] "Starting controller" logger="replicaset-controller" name="replicaset"
I0103 23:33:25.039668       1 shared_informer.go:313] Waiting for caches to sync for ReplicaSet
I0103 23:33:25.043773       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-approving-controller"
I0103 23:33:25.043841       1 certificate_controller.go:120] "Starting certificate controller" logger="certificatesigningrequest-approving-controller" name="csrapproving"
I0103 23:33:25.043872       1 shared_informer.go:313] Waiting for caches to sync for certificate-csrapproving
I0103 23:33:25.220224       1 controllermanager.go:797] "Started controller" controller="persistentvolume-binder-controller"
I0103 23:33:25.220309       1 pv_controller_base.go:308] "Starting persistent volume controller" logger="persistentvolume-binder-controller"
I0103 23:33:25.220321       1 shared_informer.go:313] Waiting for caches to sync for persistent volume
I0103 23:33:25.410940       1 controllermanager.go:797] "Started controller" controller="persistentvolumeclaim-protection-controller"
I0103 23:33:25.410980       1 pvc_protection_controller.go:105] "Starting PVC protection controller" logger="persistentvolumeclaim-protection-controller"
I0103 23:33:25.411001       1 shared_informer.go:313] Waiting for caches to sync for PVC protection
I0103 23:33:25.574383       1 controllermanager.go:797] "Started controller" controller="ephemeral-volume-controller"
I0103 23:33:25.574504       1 controller.go:173] "Starting ephemeral volume controller" logger="ephemeral-volume-controller"
I0103 23:33:25.574511       1 shared_informer.go:313] Waiting for caches to sync for ephemeral
I0103 23:33:25.659669       1 controllermanager.go:797] "Started controller" controller="legacy-serviceaccount-token-cleaner-controller"
I0103 23:33:25.659713       1 legacy_serviceaccount_token_cleaner.go:103] "Starting legacy service account token cleaner controller" logger="legacy-serviceaccount-token-cleaner-controller"
I0103 23:33:25.659722       1 shared_informer.go:313] Waiting for caches to sync for legacy-service-account-token-cleaner
I0103 23:33:25.808148       1 controllermanager.go:797] "Started controller" controller="endpointslice-mirroring-controller"
I0103 23:33:25.808222       1 endpointslicemirroring_controller.go:227] "Starting EndpointSliceMirroring controller" logger="endpointslice-mirroring-controller"
I0103 23:33:25.808245       1 shared_informer.go:313] Waiting for caches to sync for endpoint_slice_mirroring
I0103 23:33:26.002944       1 controllermanager.go:797] "Started controller" controller="disruption-controller"
I0103 23:33:26.003007       1 disruption.go:452] "Sending events to api server." logger="disruption-controller"
I0103 23:33:26.003143       1 disruption.go:463] "Starting disruption controller" logger="disruption-controller"
I0103 23:33:26.003169       1 shared_informer.go:313] Waiting for caches to sync for disruption
I0103 23:33:26.039782       1 controllermanager.go:797] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0103 23:33:26.039835       1 cleaner.go:83] "Starting CSR cleaner controller" logger="certificatesigningrequest-cleaner-controller"
I0103 23:33:26.089520       1 node_lifecycle_controller.go:430] "Controller will reconcile labels" logger="node-lifecycle-controller"
I0103 23:33:26.089554       1 controllermanager.go:797] "Started controller" controller="node-lifecycle-controller"
I0103 23:33:26.089586       1 node_lifecycle_controller.go:464] "Sending events to api server" logger="node-lifecycle-controller"
I0103 23:33:26.089595       1 node_lifecycle_controller.go:475] "Starting node controller" logger="node-lifecycle-controller"
I0103 23:33:26.089615       1 shared_informer.go:313] Waiting for caches to sync for taint
I0103 23:33:26.338600       1 controllermanager.go:797] "Started controller" controller="pod-garbage-collector-controller"
I0103 23:33:26.338728       1 gc_controller.go:99] "Starting GC controller" logger="pod-garbage-collector-controller"
I0103 23:33:26.338750       1 shared_informer.go:313] Waiting for caches to sync for GC
I0103 23:33:26.442124       1 controllermanager.go:797] "Started controller" controller="statefulset-controller"
I0103 23:33:26.442286       1 stateful_set.go:166] "Starting stateful set controller" logger="statefulset-controller"
I0103 23:33:26.442301       1 shared_informer.go:313] Waiting for caches to sync for stateful set
E0103 23:33:26.443774       1 core.go:274] "Failed to start cloud node lifecycle controller" err="no cloud provider provided" logger="cloud-node-lifecycle-controller"
I0103 23:33:26.443803       1 controllermanager.go:775] "Warning: skipping controller" controller="cloud-node-lifecycle-controller"
I0103 23:33:26.446104       1 shared_informer.go:313] Waiting for caches to sync for resource quota
I0103 23:33:26.451126       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-25-control-plane\" does not exist"
I0103 23:33:26.451274       1 shared_informer.go:320] Caches are synced for crt configmap
I0103 23:33:26.458422       1 shared_informer.go:313] Waiting for caches to sync for garbage collector
I0103 23:33:26.459759       1 shared_informer.go:320] Caches are synced for legacy-service-account-token-cleaner
I0103 23:33:26.466416       1 shared_informer.go:320] Caches are synced for TTL after finished
I0103 23:33:26.474927       1 shared_informer.go:320] Caches are synced for job
I0103 23:33:26.474951       1 shared_informer.go:320] Caches are synced for ephemeral
I0103 23:33:26.478405       1 shared_informer.go:320] Caches are synced for daemon sets
I0103 23:33:26.482741       1 shared_informer.go:320] Caches are synced for taint-eviction-controller
I0103 23:33:26.485034       1 shared_informer.go:320] Caches are synced for PV protection
I0103 23:33:26.490553       1 shared_informer.go:320] Caches are synced for taint
I0103 23:33:26.490661       1 node_lifecycle_controller.go:1232] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0103 23:33:26.490715       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-25-control-plane"
I0103 23:33:26.490736       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-client
I0103 23:33:26.490560       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kubelet-serving
I0103 23:33:26.490755       1 node_lifecycle_controller.go:1036] "Controller detected that all Nodes are not-Ready. Entering master disruption mode" logger="node-lifecycle-controller"
I0103 23:33:26.490932       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0103 23:33:26.491673       1 shared_informer.go:320] Caches are synced for certificate-csrsigning-legacy-unknown
I0103 23:33:26.494881       1 shared_informer.go:320] Caches are synced for endpoint
I0103 23:33:26.496048       1 shared_informer.go:320] Caches are synced for endpoint_slice
I0103 23:33:26.497584       1 shared_informer.go:320] Caches are synced for namespace
I0103 23:33:26.498771       1 shared_informer.go:320] Caches are synced for ReplicationController
I0103 23:33:26.498780       1 shared_informer.go:320] Caches are synced for TTL
I0103 23:33:26.501948       1 shared_informer.go:320] Caches are synced for node
I0103 23:33:26.501982       1 range_allocator.go:171] "Sending events to api server" logger="node-ipam-controller"
I0103 23:33:26.501994       1 range_allocator.go:177] "Starting range CIDR allocator" logger="node-ipam-controller"
I0103 23:33:26.501997       1 shared_informer.go:313] Waiting for caches to sync for cidrallocator
I0103 23:33:26.502000       1 shared_informer.go:320] Caches are synced for cidrallocator
I0103 23:33:26.505599       1 shared_informer.go:320] Caches are synced for HPA
I0103 23:33:26.508847       1 shared_informer.go:320] Caches are synced for endpoint_slice_mirroring
I0103 23:33:26.510307       1 shared_informer.go:320] Caches are synced for service account
I0103 23:33:26.511113       1 shared_informer.go:320] Caches are synced for PVC protection
I0103 23:33:26.520710       1 shared_informer.go:320] Caches are synced for persistent volume
I0103 23:33:26.536247       1 shared_informer.go:320] Caches are synced for bootstrap_signer
I0103 23:33:26.539652       1 shared_informer.go:320] Caches are synced for GC
I0103 23:33:26.542884       1 shared_informer.go:320] Caches are synced for stateful set
I0103 23:33:26.544097       1 shared_informer.go:320] Caches are synced for attach detach
I0103 23:33:26.544122       1 shared_informer.go:320] Caches are synced for certificate-csrapproving
I0103 23:33:26.548226       1 shared_informer.go:320] Caches are synced for expand
I0103 23:33:26.577829       1 shared_informer.go:320] Caches are synced for cronjob
I0103 23:33:26.665665       1 shared_informer.go:320] Caches are synced for ClusterRoleAggregator
I0103 23:33:26.667065       1 shared_informer.go:320] Caches are synced for validatingadmissionpolicy-status
I0103 23:33:26.690693       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-25-control-plane" podCIDRs=["10.244.0.0/24"]
I0103 23:33:26.690729       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:26.690759       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:26.703402       1 shared_informer.go:320] Caches are synced for disruption
I0103 23:33:26.732064       1 shared_informer.go:320] Caches are synced for resource quota
I0103 23:33:26.739981       1 shared_informer.go:320] Caches are synced for ReplicaSet
I0103 23:33:26.746740       1 shared_informer.go:320] Caches are synced for resource quota
I0103 23:33:26.774318       1 shared_informer.go:320] Caches are synced for deployment
I0103 23:33:27.159044       1 shared_informer.go:320] Caches are synced for garbage collector
I0103 23:33:27.189248       1 shared_informer.go:320] Caches are synced for garbage collector
I0103 23:33:27.189284       1 garbagecollector.go:157] "All resource monitors have synced. Proceeding to collect garbage" logger="garbage-collector-controller"
I0103 23:33:27.387434       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:28.151734       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="449.100461ms"
I0103 23:33:28.151982       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="451.068428ms"
I0103 23:33:28.254210       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="102.207995ms"
I0103 23:33:28.254330       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="40.602µs"
I0103 23:33:28.254376       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="102.580909ms"
I0103 23:33:28.254445       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="47.602µs"
I0103 23:33:31.359416       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-25-worker\" does not exist"
I0103 23:33:31.491193       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-25-worker" podCIDRs=["10.244.1.0/24"]
I0103 23:33:31.491232       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:31.491253       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:31.512024       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:31.563364       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-25-worker"
I0103 23:33:31.971491       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"response-25-worker2\" does not exist"
I0103 23:33:31.993865       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="response-25-worker2" podCIDRs=["10.244.2.0/24"]
I0103 23:33:31.993903       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:31.993936       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:32.201948       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:32.245732       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:32.362788       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:33.477658       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:33.958540       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="261.112268ms"
I0103 23:33:34.319989       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="361.288964ms"
I0103 23:33:34.340833       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="382.250793ms"
I0103 23:33:34.340915       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="34.401µs"
I0103 23:33:34.414973       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="94.950802ms"
I0103 23:33:34.415042       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="26.101µs"
I0103 23:33:36.564380       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="response-25-worker2"
I0103 23:33:41.156261       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:41.169613       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:41.190936       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="81.903µs"
I0103 23:33:41.207122       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="88.403µs"
I0103 23:33:41.207234       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="29.701µs"
I0103 23:33:41.228282       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="40.101µs"
I0103 23:33:41.254681       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="66.803µs"
I0103 23:33:41.319348       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="77.002µs"
I0103 23:33:41.627621       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-control-plane"
I0103 23:33:41.627669       1 node_lifecycle_controller.go:1055] "Controller detected that some Nodes are Ready. Exiting master disruption mode" logger="node-lifecycle-controller"
I0103 23:33:41.669896       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:49.224252       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-25-worker"
I0103 23:33:49.224378       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:49.302709       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:33:50.140910       1 topologycache.go:237] "Can't get CPU or zone information for node" logger="endpointslice-controller" node="response-25-worker"
I0103 23:33:50.140994       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:50.212767       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker2"
I0103 23:33:50.672543       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="54.502µs"
I0103 23:33:50.828963       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="56.81828ms"
I0103 23:33:50.920101       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="91.018171ms"
I0103 23:33:50.920177       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="kube-system/coredns-6f6b679f8f" duration="34.101µs"
I0103 23:33:51.677717       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="7.75477ms"
I0103 23:33:51.677789       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="local-path-storage/local-path-provisioner-57c5987fd4" duration="22.601µs"
I0103 23:34:00.423400       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="35.601µs"
I0103 23:34:00.423473       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="23.1µs"
I0103 23:34:00.505700       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="34.802µs"
I0103 23:34:00.537643       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="35.801µs"
I0103 23:34:16.835933       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/wordpress-b8c9d796b" duration="40.707µs"
I0103 23:34:23.595023       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="29.801µs"
I0103 23:34:32.836004       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="response-25-worker"
I0103 23:34:45.786923       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="26.25916ms"
I0103 23:34:45.786998       1 replica_set.go:679] "Finished syncing" logger="replicaset-controller" kind="ReplicaSet" key="wordpress-namespace/mysql-d9955d5c5" duration="23.601µs"
==== END logs for container kube-controller-manager of pod kube-system/kube-controller-manager-response-25-control-plane ====
